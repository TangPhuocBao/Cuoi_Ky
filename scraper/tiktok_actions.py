from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from datetime import datetime, timezone
import json
import os
import time
import random
from typing import Any, Dict, List, Optional
from urllib.parse import quote
import logging

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class TikTokSeleniumScraper:
    def __init__(
        self,
        headless: bool = True,
        sleep_min: float = 3.0,
        sleep_max: float = 5.0,
        pause_every: int = 50,
        pause_seconds: float = 2.0,
        max_retries: int = 3,
    ):
        self.driver: Optional[webdriver.Chrome] = None
        self.headless = headless
        self.sleep_min = sleep_min
        self.sleep_max = sleep_max
        self.pause_every = pause_every
        self.pause_seconds = pause_seconds
        self.max_retries = max_retries

    def initialize(self) -> bool:
        """Kh·ªüi t·∫°o Selenium WebDriver."""
        try:
            chrome_options = Options()
            
            if self.headless:
                chrome_options.add_argument("--headless=new")
            
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument("--disable-blink-features=AutomationControlled")
            chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option("useAutomationExtension", False)
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.set_page_load_timeout(30)
            
            logger.info(f"‚úì ƒê√£ kh·ªüi t·∫°o Selenium WebDriver th√†nh c√¥ng! (headless={self.headless})")
            return True
            
        except Exception as e:
            logger.error(f"‚úó L·ªói khi kh·ªüi t·∫°o WebDriver: {e}")
            logger.error("‚ö†Ô∏è  C·∫ßn c√†i ƒë·∫∑t ChromeDriver ho·∫∑c webdriver-manager")
            logger.error("   pip install selenium webdriver-manager")
            return False

    def close(self):
        """ƒê√≥ng WebDriver."""
        try:
            if self.driver:
                self.driver.quit()
                logger.info("‚úì WebDriver ƒë√£ ƒë√≥ng")
        except Exception as e:
            logger.error(f"L·ªói khi ƒë√≥ng WebDriver: {e}")

    @staticmethod
    def random_sleep():
        """Sleep v·ªõi th·ªùi gian random gi·ªØa sleep_min v√† sleep_max."""
        pass

    def random_sleep_instance(self):
        """Sleep v·ªõi th·ªùi gian random gi·ªØa sleep_min v√† sleep_max."""
        sleep_time = random.uniform(self.sleep_min, self.sleep_max)
        time.sleep(sleep_time)
        logger.debug(f"üí§ Sleep {sleep_time:.2f}s")

    def scroll_to_load_videos(self, target_count: int = 3000, max_scroll: int = 100) -> List[Dict[str, Any]]:
        """Scroll trang ƒë·ªÉ load video."""
        videos = []
        seen_ids = set()
        collected = 0
        scroll_count = 0

        try:
            while collected < target_count and scroll_count < max_scroll:
                # L·∫•y t·∫•t c·∫£ video hi·ªán c√≥ tr√™n trang
                try:
                    video_elements = self.driver.find_elements(By.CSS_SELECTOR, "[data-e2e='video-card']")
                    
                    for video_elem in video_elements:
                        if collected >= target_count:
                            break

                        try:
                            # L·∫•y link video
                            link_elem = video_elem.find_element(By.CSS_SELECTOR, "a[href*='/video/']")
                            video_url = link_elem.get_attribute("href")
                            video_id = video_url.split("/video/")[-1].split("?")[0] if video_url else None

                            if not video_id or video_id in seen_ids:
                                continue

                            # Parse th√¥ng tin t·ª´ element
                            info = self._parse_video_element(video_elem, video_url)
                            
                            if info and info.get("video_id"):
                                seen_ids.add(video_id)
                                videos.append(info)
                                collected += 1

                                desc = (info.get("description") or "")[:60].replace("\n", " ")
                                logger.info(f"[{collected}] {desc}...")

                                # Pause nh·∫π
                                if self.pause_every > 0 and (collected % self.pause_every == 0):
                                    time.sleep(self.pause_seconds)
                                    logger.info(f"‚è∏Ô∏è  Pause {self.pause_seconds}s")

                        except Exception as e:
                            logger.debug(f"L·ªói parse video element: {e}")
                            continue

                except Exception as e:
                    logger.error(f"L·ªói l·∫•y video elements: {e}")

                # Scroll xu·ªëng
                if collected < target_count:
                    self.driver.execute_script("window.scrollBy(0, 500);")
                    scroll_count += 1
                    self.random_sleep_instance()

            logger.info(f"‚úì ƒê√£ t·∫£i {collected}/{target_count} video sau {scroll_count} l·∫ßn scroll")
            return videos

        except Exception as e:
            logger.error(f"L·ªói trong qu√° tr√¨nh scroll: {e}")
            return videos

    def _parse_video_element(self, video_elem, video_url: str) -> Optional[Dict[str, Any]]:
        """√âp video element v·ªÅ dict g·ªçn g√†ng."""
        try:
            video_id = video_url.split("/video/")[-1].split("?")[0] if video_url else ""

            # L·∫•y description t·ª´ title
            try:
                desc_elem = video_elem.find_element(By.CSS_SELECTOR, "[data-e2e='video-desc']")
                description = desc_elem.text or ""
            except:
                description = ""

            # L·∫•y t√™n t√°c gi·∫£
            try:
                author_elem = video_elem.find_element(By.CSS_SELECTOR, "a[href*='/@']")
                author_url = author_elem.get_attribute("href")
                author = author_url.split("/@")[-1].split("?")[0] if author_url else ""
            except:
                author = ""

            # L·∫•y stats (likes, comments, shares, views)
            likes = self._extract_stat(video_elem, "like")
            comments = self._extract_stat(video_elem, "comment")
            shares = self._extract_stat(video_elem, "share")
            views = self._extract_stat(video_elem, "view")

            # L·∫•y th√¥ng tin kh√°c t·ª´ page (n·∫øu c·∫ßn chi ti·∫øt h∆°n)
            hashtags = []
            music = ""
            duration = 0

            create_time_utc = datetime.now(tz=timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
            create_ts = int(datetime.now(tz=timezone.utc).timestamp())

            return {
                "video_id": video_id,
                "description": description,
                "author": author,
                "author_nickname": author,
                "author_verified": False,
                "music": music,
                "music_author": "",
                "likes": likes,
                "comments": comments,
                "shares": shares,
                "views": views,
                "duration": duration,
                "hashtags": hashtags,
                "create_time_utc": create_time_utc,
                "create_ts": create_ts,
                "video_url": video_url,
                "comments_data": []  # Th√™m tr∆∞·ªùng comments_data tr·ªëng
            }

        except Exception as e:
            logger.error(f"L·ªói parse video element: {e}")
            return None

    @staticmethod
    def _extract_stat(video_elem, stat_type: str) -> int:
        """L·∫•y s·ªë li·ªáu th·ªëng k√™ (likes, comments, etc)."""
        try:
            stat_elem = video_elem.find_element(By.XPATH, f".//*[contains(@data-e2e, '{stat_type}')]")
            text = stat_elem.text or "0"
            
            # Parse s·ªë li·ªáu (x·ª≠ l√Ω ƒë·ªãnh d·∫°ng K, M)
            text = text.lower().strip()
            if 'k' in text:
                return int(float(text.replace('k', '')) * 1000)
            elif 'm' in text:
                return int(float(text.replace('m', '')) * 1000000)
            else:
                return int(''.join(filter(str.isdigit, text)) or 0)
        except:
            return 0

    def get_video_comments(self, video_url: str, max_comments: int = 100) -> List[Dict[str, Any]]:
        """
        L·∫•y danh s√°ch comment t·ª´ m·ªôt video TikTok.
        
        Args:
            video_url: URL c·ªßa video TikTok
            max_comments: S·ªë l∆∞·ª£ng comment t·ªëi ƒëa c·∫ßn l·∫•y
            
        Returns:
            Danh s√°ch comment v·ªõi th√¥ng tin chi ti·∫øt
        """
        logger.info(f"üí¨ ƒêang l·∫•y comment t·ª´ video: {video_url}")
        comments = []
        
        try:
            # M·ªü video trong tab m·ªõi
            original_window = self.driver.current_window_handle
            self.driver.execute_script("window.open('');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            
            self.driver.get(video_url)
            time.sleep(5)  # Ch·ªù trang t·∫£i
            
            # Cu·ªôn xu·ªëng ƒë·ªÉ load comment section
            self.driver.execute_script("window.scrollBy(0, 800);")
            time.sleep(2)
            
            # T√¨m v√† click v√†o ph·∫ßn comment ƒë·ªÉ m·ªü r·ªông
            try:
                # Th·ª≠ t√¨m n√∫t xem th√™m comment
                comment_section = self.driver.find_element(By.CSS_SELECTOR, "[data-e2e='comment-container']")
                comment_section.click()
                time.sleep(2)
            except:
                logger.debug("Kh√¥ng t√¨m th·∫•y n√∫t comment, ti·∫øp t·ª•c...")
            
            # Scroll ƒë·ªÉ load th√™m comment
            scroll_attempts = 0
            max_scroll_attempts = 20
            
            while len(comments) < max_comments and scroll_attempts < max_scroll_attempts:
                # T√¨m t·∫•t c·∫£ comment elements
                try:
                    comment_elements = self.driver.find_elements(By.CSS_SELECTOR, "[data-e2e='comment-item']")
                    
                    for comment_elem in comment_elements:
                        if len(comments) >= max_comments:
                            break
                            
                        try:
                            comment_info = self._parse_comment_element(comment_elem)
                            if comment_info:
                                # Ki·ªÉm tra comment ƒë√£ t·ªìn t·∫°i ch∆∞a
                                comment_id = comment_info.get("comment_id")
                                if comment_id and comment_id not in [c.get("comment_id") for c in comments]:
                                    comments.append(comment_info)
                                    logger.debug(f"ƒê√£ l·∫•y comment {len(comments)}/{max_comments}: {comment_info.get('text', '')[:50]}...")
                        except Exception as e:
                            logger.debug(f"L·ªói parse comment: {e}")
                            continue
                            
                except Exception as e:
                    logger.debug(f"Kh√¥ng t√¨m th·∫•y comment elements: {e}")
                
                # Scroll xu·ªëng ƒë·ªÉ load th√™m comment
                self.driver.execute_script("window.scrollBy(0, 300);")
                scroll_attempts += 1
                time.sleep(1)
                
                # Ki·ªÉm tra xem c√≥ th√™m comment m·ªõi kh√¥ng
                if len(comment_elements) >= max_comments:
                    break
            
            logger.info(f"‚úì ƒê√£ l·∫•y {len(comments)} comment t·ª´ video")
            
            # ƒê√≥ng tab v√† quay l·∫°i tab g·ªëc
            self.driver.close()
            self.driver.switch_to.window(original_window)
            
            return comments
            
        except Exception as e:
            logger.error(f"‚úó L·ªói khi l·∫•y comment: {e}")
            
            # C·ªë g·∫Øng quay l·∫°i tab g·ªëc n·∫øu c√≥ l·ªói
            try:
                if len(self.driver.window_handles) > 1:
                    self.driver.close()
                self.driver.switch_to.window(original_window)
            except:
                pass
                
            return comments

    def _parse_comment_element(self, comment_elem) -> Optional[Dict[str, Any]]:
        """Parse th√¥ng tin t·ª´ m·ªôt comment element."""
        try:
            # L·∫•y comment ID
            comment_id = comment_elem.get_attribute("data-comment-id") or ""
            if not comment_id:
                # T·∫°o ID t·ª´ timestamp n·∫øu kh√¥ng c√≥
                comment_id = f"comment_{int(time.time() * 1000)}"
            
            # L·∫•y t√™n ng∆∞·ªùi comment
            try:
                username_elem = comment_elem.find_element(By.CSS_SELECTOR, "[data-e2e='comment-username']")
                username = username_elem.text or ""
            except:
                username = ""
            
            # L·∫•y n·ªôi dung comment
            try:
                text_elem = comment_elem.find_element(By.CSS_SELECTOR, "[data-e2e='comment-text']")
                text = text_elem.text or ""
            except:
                text = ""
            
            # L·∫•y s·ªë like c·ªßa comment
            try:
                likes_elem = comment_elem.find_element(By.CSS_SELECTOR, "[data-e2e='comment-like-count']")
                likes_text = likes_elem.text or "0"
                likes = int(''.join(filter(str.isdigit, likes_text)) or 0)
            except:
                likes = 0
            
            # L·∫•y th·ªùi gian comment
            try:
                time_elem = comment_elem.find_element(By.CSS_SELECTOR, "[data-e2e='comment-time']")
                time_text = time_elem.text or ""
            except:
                time_text = ""
            
            # L·∫•y link avatar (n·∫øu c√≥)
            try:
                avatar_elem = comment_elem.find_element(By.CSS_SELECTOR, "img[src*='tiktok']")
                avatar_url = avatar_elem.get_attribute("src") or ""
            except:
                avatar_url = ""
            
            # Ki·ªÉm tra xem c√≥ ph·∫£i t√°c gi·∫£ video comment kh√¥ng
            is_author = False
            try:
                author_badge = comment_elem.find_element(By.CSS_SELECTOR, "[data-e2e='comment-author-badge']")
                is_author = bool(author_badge)
            except:
                pass
            
            # T·∫°o timestamp
            timestamp = int(time.time())
            
            return {
                "comment_id": comment_id,
                "username": username,
                "text": text,
                "likes": likes,
                "time_text": time_text,
                "avatar_url": avatar_url,
                "is_author": is_author,
                "timestamp": timestamp,
                "collected_at": datetime.now(tz=timezone.utc).strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            logger.debug(f"L·ªói parse comment element: {e}")
            return None

    async def get_videos_with_comments(
        self, 
        mode: str = "trending", 
        keyword: str = "", 
        target_videos: int = 10, 
        comments_per_video: int = 20
    ) -> List[Dict[str, Any]]:
        """
        L·∫•y video k√®m theo comment c·ªßa m·ªói video.
        
        Args:
            mode: Ch·∫ø ƒë·ªô l·∫•y video ('trending', 'search', 'hashtag', 'user')
            keyword: T·ª´ kh√≥a t√¨m ki·∫øm ho·∫∑c username/hashtag t√πy mode
            target_videos: S·ªë video t·ªëi ƒëa c·∫ßn l·∫•y
            comments_per_video: S·ªë comment t·ªëi ƒëa cho m·ªói video
            
        Returns:
            Danh s√°ch video v·ªõi comment ƒë·∫ßy ƒë·ªß
        """
        logger.info(f"üéØ L·∫•y {target_videos} video v·ªõi {comments_per_video} comment m·ªói video")
        
        # L·∫•y danh s√°ch video
        videos = []
        if mode == "trending":
            videos = await self.get_trending(target_count=target_videos)
        elif mode == "search":
            videos = await self.search_videos(keyword, target_count=target_videos)
        elif mode == "hashtag":
            videos = await self.hashtag_videos(keyword, target_count=target_videos)
        elif mode == "user":
            videos = await self.user_videos(keyword, target_count=target_videos)
        
        # L·∫•y comment cho t·ª´ng video
        for i, video in enumerate(videos):
            logger.info(f"üì• ƒêang l·∫•y comment cho video {i+1}/{len(videos)}: {video.get('video_id', '')}")
            
            video_url = video.get("video_url")
            if video_url:
                comments = self.get_video_comments(video_url, max_comments=comments_per_video)
                video["comments_data"] = comments
                video["total_comments_collected"] = len(comments)
                
                # In th√¥ng tin t√≥m t·∫Øt
                if comments:
                    logger.info(f"   ‚úì ƒê√£ l·∫•y {len(comments)} comment")
                    for j, comment in enumerate(comments[:3]):  # Hi·ªÉn th·ªã 3 comment ƒë·∫ßu
                        logger.info(f"      {j+1}. @{comment.get('username', '')}: {comment.get('text', '')[:50]}...")
                    if len(comments) > 3:
                        logger.info(f"      ... v√† {len(comments) - 3} comment kh√°c")
            else:
                logger.warning(f"   ‚úó Video kh√¥ng c√≥ URL")
            
            # D·ª´ng gi·ªØa c√°c video ƒë·ªÉ tr√°nh b·ªã block
            if i < len(videos) - 1:
                sleep_time = random.uniform(5, 10)
                logger.info(f"‚è≥ Ch·ªù {sleep_time:.1f}s tr∆∞·ªõc khi l·∫•y video ti·∫øp theo...")
                time.sleep(sleep_time)
        
        return videos

    async def get_trending(self, target_count: int = 3000, autosave_path: Optional[str] = None, autosave_every: int = 100):
        """L·∫•y video trending."""
        logger.info(f"üî• ƒêang l·∫•y t·ªëi ƒëa {target_count} video trending...")
        
        try:
            self.driver.get("https://www.tiktok.com/explore")
            time.sleep(5)
            
            videos = self.scroll_to_load_videos(target_count=target_count)
            
            if autosave_path:
                save_json(videos, autosave_path)
            
            return videos

        except Exception as e:
            logger.error(f"L·ªói get_trending: {e}")
            return []

    async def search_videos(self, keyword: str, target_count: int = 3000, autosave_path: Optional[str] = None, autosave_every: int = 100):
        """T√¨m ki·∫øm video."""
        logger.info(f"üîç ƒêang t√¨m ki·∫øm '{keyword}' (t·ªëi ƒëa {target_count} video)...")
        
        try:
            search_url = f"https://www.tiktok.com/search/video?q={quote(keyword)}"
            self.driver.get(search_url)
            time.sleep(5)
            
            videos = self.scroll_to_load_videos(target_count=target_count)
            
            if autosave_path:
                save_json(videos, autosave_path)
            
            return videos

        except Exception as e:
            logger.error(f"L·ªói search_videos: {e}")
            return []

    async def hashtag_videos(self, hashtag: str, target_count: int = 3000, autosave_path: Optional[str] = None, autosave_every: int = 100):
        """L·∫•y video t·ª´ hashtag."""
        logger.info(f"üè∑  ƒêang l·∫•y video t·ª´ hashtag #{hashtag} (t·ªëi ƒëa {target_count})...")
        
        try:
            hashtag_url = f"https://www.tiktok.com/tag/{quote(hashtag)}"
            self.driver.get(hashtag_url)
            time.sleep(5)
            
            videos = self.scroll_to_load_videos(target_count=target_count)
            
            if autosave_path:
                save_json(videos, autosave_path)
            
            return videos

        except Exception as e:
            logger.error(f"L·ªói hashtag_videos: {e}")
            return []

    async def user_videos(self, username: str, target_count: int = 3000, autosave_path: Optional[str] = None, autosave_every: int = 100):
        """L·∫•y video t·ª´ user."""
        logger.info(f"üë§ ƒêang l·∫•y video t·ª´ @{username} (t·ªëi ƒëa {target_count})...")
        
        try:
            user_url = f"https://www.tiktok.com/@{username}"
            self.driver.get(user_url)
            time.sleep(5)
            
            videos = self.scroll_to_load_videos(target_count=target_count)
            
            if autosave_path:
                save_json(videos, autosave_path)
            
            return videos

        except Exception as e:
            logger.error(f"L·ªói user_videos: {e}")
            return []


def save_json(data: List[Dict[str, Any]], filename: str, quiet: bool = False):
    """L∆∞u d·ªØ li·ªáu v√†o JSON."""
    os.makedirs(os.path.dirname(filename) or ".", exist_ok=True)
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    if not quiet:
        logger.info(f"üíæ ƒê√£ l∆∞u {len(data)} video v√†o file: {filename}")


def print_stats(videos: List[Dict[str, Any]]):
    """In th·ªëng k√™."""
    if not videos:
        logger.warning("‚ö†Ô∏è  Kh√¥ng c√≥ video ƒë·ªÉ th·ªëng k√™")
        return

    total_views = sum(int(v.get("views", 0) or 0) for v in videos)
    total_likes = sum(int(v.get("likes", 0) or 0) for v in videos)
    total_comments = sum(int(v.get("comments", 0) or 0) for v in videos)
    total_shares = sum(int(v.get("shares", 0) or 0) for v in videos)
    
    # T√≠nh t·ªïng comment ƒë√£ thu th·∫≠p
    total_comments_collected = sum(len(v.get("comments_data", [])) for v in videos)

    n = len(videos)
    logger.info("\nüìä TH·ªêNG K√ä:")
    logger.info(f"   ‚Ä¢ S·ªë video: {n}")
    logger.info(f"   ‚Ä¢ T·ªïng views: {total_views:,}")
    logger.info(f"   ‚Ä¢ T·ªïng likes: {total_likes:,}")
    logger.info(f"   ‚Ä¢ T·ªïng comments (theo video): {total_comments:,}")
    logger.info(f"   ‚Ä¢ T·ªïng shares: {total_shares:,}")
    logger.info(f"   ‚Ä¢ T·ªïng comment ƒë√£ thu th·∫≠p: {total_comments_collected:,}")
    
    if n > 0:
        logger.info(f"   ‚Ä¢ TB views/video: {(total_views // n):,}")
        logger.info(f"   ‚Ä¢ TB likes/video: {(total_likes // n):,}")
        logger.info(f"   ‚Ä¢ TB comment thu th·∫≠p/video: {(total_comments_collected // n):,}")


async def main():
    """Main function."""
    scraper = TikTokSeleniumScraper(
        headless=False,  # ƒê·ªÉ headless=False ƒë·ªÉ d·ªÖ debug khi l·∫•y comment
        sleep_min=3.0,
        sleep_max=5.0,
        pause_every=50,
        pause_seconds=2.0,
        max_retries=3,
    )

    if not scraper.initialize():
        return

    try:
        logger.info("=" * 70)
        logger.info("1. Trending")
        logger.info("2. Search theo t·ª´ kh√≥a")
        logger.info("3. Hashtag")
        logger.info("4. User")
        logger.info("5. L·∫•y video v·ªõi comment (ch·∫ø ƒë·ªô n√¢ng cao)")
        logger.info("=" * 70)

        choice = input("Ch·ªçn ch·∫ø ƒë·ªô (1-5) [m·∫∑c ƒë·ªãnh: 1]: ").strip() or "1"
        
        if choice == "5":
            # Ch·∫ø ƒë·ªô l·∫•y video v·ªõi comment
            logger.info("\nüéØ CH·∫æ ƒê·ªò L·∫§Y VIDEO V·ªöI COMMENT")
            logger.info("1. Trending")
            logger.info("2. Search theo t·ª´ kh√≥a")
            logger.info("3. Hashtag")
            logger.info("4. User")
            
            mode_choice = input("Ch·ªçn ngu·ªìn video (1-4) [m·∫∑c ƒë·ªãnh: 1]: ").strip() or "1"
            
            mode_map = {"1": "trending", "2": "search", "3": "hashtag", "4": "user"}
            mode = mode_map.get(mode_choice, "trending")
            
            keyword = ""
            if mode in ["search", "hashtag", "user"]:
                prompt_text = {
                    "search": "Nh·∫≠p t·ª´ kh√≥a t√¨m ki·∫øm",
                    "hashtag": "Nh·∫≠p hashtag (kh√¥ng c·∫ßn #)",
                    "user": "Nh·∫≠p username (kh√¥ng c·∫ßn @)"
                }
                keyword = input(f"{prompt_text[mode]}: ").strip()
            
            target_videos = int(input("S·ªë video t·ªëi ƒëa [m·∫∑c ƒë·ªãnh: 10]: ").strip() or "10")
            comments_per_video = int(input("S·ªë comment t·ªëi ƒëa m·ªói video [m·∫∑c ƒë·ªãnh: 20]: ").strip() or "20")
            
            videos = await scraper.get_videos_with_comments(
                mode=mode,
                keyword=keyword,
                target_videos=target_videos,
                comments_per_video=comments_per_video
            )
            
        else:
            # Ch·∫ø ƒë·ªô c≈© ch·ªâ l·∫•y video
            target_str = input("S·ªë video t·ªëi ƒëa [m·∫∑c ƒë·ªãnh: 3000]: ").strip() or "3000"
            target_count = int(target_str)

            autosave_path = "out/tiktok_autosave.json"
            autosave_every = 100

            videos: List[Dict[str, Any]] = []

            if choice == "1":
                videos = await scraper.get_trending(
                    target_count=target_count,
                    autosave_path=autosave_path,
                    autosave_every=autosave_every,
                )

            elif choice == "2":
                kw = input("Nh·∫≠p t·ª´ kh√≥a: ").strip()
                if kw:
                    videos = await scraper.search_videos(
                        kw,
                        target_count=target_count,
                        autosave_path=autosave_path,
                        autosave_every=autosave_every,
                    )

            elif choice == "3":
                tag = input("Nh·∫≠p hashtag (kh√¥ng c·∫ßn #): ").strip()
                if tag:
                    videos = await scraper.hashtag_videos(
                        tag,
                        target_count=target_count,
                        autosave_path=autosave_path,
                        autosave_every=autosave_every,
                    )

            elif choice == "4":
                username = input("Nh·∫≠p username (kh√¥ng c·∫ßn @): ").strip()
                if username:
                    videos = await scraper.user_videos(
                        username,
                        target_count=target_count,
                        autosave_path=autosave_path,
                        autosave_every=autosave_every,
                    )

        if not videos:
            logger.warning("\n‚ö†Ô∏è  Kh√¥ng l·∫•y ƒë∆∞·ª£c video n√†o.")
            return

        print_stats(videos)

        # Hi·ªÉn th·ªã comment statistics
        total_comments = sum(len(v.get("comments_data", [])) for v in videos)
        if total_comments > 0:
            logger.info("\nüí¨ TH·ªêNG K√ä COMMENT:")
            logger.info(f"   ‚Ä¢ T·ªïng s·ªë comment thu th·∫≠p: {total_comments}")
            
            # T√¨m video c√≥ nhi·ªÅu comment nh·∫•t
            max_comments_video = max(videos, key=lambda x: len(x.get("comments_data", [])))
            max_comments = len(max_comments_video.get("comments_data", []))
            logger.info(f"   ‚Ä¢ Video nhi·ªÅu comment nh·∫•t: {max_comments} comment")
            
            # Hi·ªÉn th·ªã m·ªôt s·ªë comment m·∫´u
            logger.info("\nüìù COMMENT M·∫™U:")
            for i, video in enumerate(videos[:3]):  # L·∫•y 3 video ƒë·∫ßu
                comments = video.get("comments_data", [])
                if comments:
                    logger.info(f"\nVideo {i+1} ({video.get('video_id', '')}):")
                    for j, comment in enumerate(comments[:2]):  # 2 comment ƒë·∫ßu m·ªói video
                        logger.info(f"   {j+1}. @{comment.get('username', '')}: {comment.get('text', '')[:80]}...")

        save = input("\nL∆∞u JSON cu·ªëi c√πng? (y/n) [m·∫∑c ƒë·ªãnh: y]: ").strip().lower()
        if save != "n":
            default_name = f"out/tiktok_{len(videos)}_videos_with_comments.json" if total_comments > 0 else f"out/tiktok_{len(videos)}_videos.json"
            filename = input(f"T√™n file [m·∫∑c ƒë·ªãnh: {default_name}]: ").strip() or default_name
            save_json(videos, filename)

    finally:
        logger.info("\nüîÑ ƒê√≥ng WebDriver...")
        scraper.close()
        logger.info("‚úì Xong!")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
